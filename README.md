# Visualizing-deepCNNfeatures-retinal-images2019-2020

This project is about exploring the features learned by a deep convolutional neural network trained with images of the retinal fundus in order to understand the reason why the model classifies an image in a certain severity level of a disease known as Diabetic Retinopathy.

First, there is a brief explanation of the motivation to develop this project and then a detailed description about the images preprocessing, the arquitecture of the network, the parameters of its training, and the technique used to visualize and explain the internal representations learned by the model called Grad-CAM.

# Motivation 

The implementation of deep convolutional neural networks to extract relevant features and important information from medical images for disease diagnosis has been increasing for several years. One of the most widely researched areas of imaging is the diagnosis of Diabetic Retinopathy (DR), which is one of the complications of diabetes and one of the main causes of blindness. 

Diagnosis of DR requires a detailed analysis of retinal fundus photographs. This task, performed by medical experts, turns out to be a costly and time-consuming activity and can lead to misdiagnosis due to visual fatigue. For this reason, the implementation of computer-aided medical diagnosis (CAD) tools that apply artificial intelligence algorithms to provide a second diagnosis of any disease is proposed. 

However, in many occasions the results generated by these algorithms present little explanation and clarity, which results in lack of interpretability and difficulty of understanding for medical experts. Due to this, the need arises to implement methods that allow to obtain a better idea of what happens inside these automatic and deep learning algorithms to know the internal representations and processes that they perform for decision making.

# Image Preprocessing

Se utilizó la base de datos facilitada por EyePACS, una aplicación web para el intercambio de información clínica relacionada con los ojos, y compartida en una competencia de Kaggle denominada Diabetic Retinopathy Detection en 2015.

La base de datos consistía en un conjunto de gran tamaño de imágenes de retina (aproximadamente 88.000) de alta resolución (entre 4 y 14 megapíxeles) tomadas bajo diferentes condiciones de captura. Estas imágenes fueron etiquetadas por un clínico con un nivel de retinopatía diabética en una escala de 0 a 4 (ver Tabla abajo).

| Class | DR Level |
| ----- | -------- |
| 0     | No DR    |
| 1     | Mild     |
| 2     | Moderate |
| 3     | Severe   |
| 4     | Proliferative DR |

El preprocesamiento de las imágenes consistió en diversos métodos: primero, se cortaron las imágenes para eliminar el exceso de fondo negro que poseían y de esta manera que la retina quedase ubicada en el centro de la imagen; segundo, se realizó un proceso conocido como escalamiento del radio con el objetivo de que todas las imágenes tuviesen radios similares; tercero, se mapearon los colores de las imágenes al 50% de la escala de gris para que tanto el fondo de la imagen como el de la retina tuviesen tonalidades similares y se resaltaran más los detalles del interior de la retina; cuarto, fue necesario eliminar el borde de la circunferencia de la retina que quedó resaltado como resultado del proceso anterior; quinto, se redimensionaron las imágenes para que tuvieran una forma cuadrada con dimensiones 512x512 píxeles.

![image](https://user-images.githubusercontent.com/82721764/148121688-c98c5db4-b6ee-4157-99bb-350139bc7ba4.png)


Tanto el preprocesamiento de las imágenes como el diseño de la arquitectura de la red fue realizado por @isa-tr

# Proposed Network 

La arquitectura de la red neuronal convolucional utilizada en el proyecto fue basada en la propuesta del equipo de DeepSense quienes ocuparon el sexto puesto en la competencia de Kaggle con algunos cambios como se puede observar en la siguiente imagen. 

![image](https://user-images.githubusercontent.com/82721764/148122372-f5030100-fec0-44af-9ff7-f5c766a98f7d.png)

En la siguiente tabla se detalla la configuración de parámetros para cada capa de la red neuronal.

![image](https://user-images.githubusercontent.com/82721764/148122475-0791fffe-cc5e-46d4-b91b-25d1f6f3fe37.png)

# Implementation of Gradient-weighted Class Activation Mapping (Grad-CAM)




